{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fc15eb7",
   "metadata": {},
   "source": [
    "Alex-Net（2012）\n",
    "引起此次深度学习热潮的第一个网络\n",
    "此前更为广泛应用的是核方法（支持向量机SVM）2000年左右，SVM为凸优化模型，模型理论完备\n",
    "Alex-Net是更粗更深的Le-Net,11-11的卷积核替换5-5的卷积核，3-3的最大池化替换2-2的平均池化，relu激活替换sig激活（relu激活能够避免Loss梯度消失问题，在零处导数为1），并且添加了几个卷积层，使用了丢弃法和数据增强。针对的数据集也从简单的黑白图像50000-10000（Fashion-MNIST）或手写数据集转换为RGB的复杂现实图像Image-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82301d96",
   "metadata": {},
   "source": [
    "le-Net和Alex-Net都是卷积层与池化层组合形成的，VGG网络则是将多个卷积（3*3 padding=1,stride=1）和最大池化（3*3 padding=2）（宽度减半）作为VGG块，多个VGG块组成VGG网络，VGG-16代表卷积层个数。\n",
    "le-Net Alex-Net VGG最终都需要全连接层，导致最终参数数目过大（与像素数有关），很容易过拟合，因此出现了一种不需要全连接层的网络，NiN(网络中的网络)，NiN用一个卷积层加两个1*1的卷积层组成块，多个块+最大池化组成网络，最终用全局池化输出类。1*1的卷积相当于对输入输出通道每个像素点做全连接，大大减小了参数数目，模型简单且不容易过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3c3c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8cdb606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b314876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b8950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24685e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93077a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b58a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd8ad5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c17e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a237b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9042bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformCom=trans.Compose([trans.Resize(224),trans.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c026390",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet=torchvision.datasets.FashionMNIST('../',train=True,download=False,transform=transformCom)\n",
    "testSet=torchvision.datasets.FashionMNIST('../',train=False,download=False,transform=transformCom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55467df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader=data.DataLoader(trainSet,batch_size=128,shuffle=True)\n",
    "testLoader=data.DataLoader(testSet,batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d7ac7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AlexeNET网络，relu激活\n",
    "AlexNet=torch.nn.Sequential(\n",
    "      nn.Conv2d(1,96,kernel_size=11,stride=4,padding=2),nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=3,stride=2), # \n",
    "      nn.Conv2d(96,128*2,kernel_size=5,padding=2),nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "      nn.Conv2d(128*2,192*2,kernel_size=3,padding=1),nn.ReLU(),\n",
    "      nn.Conv2d(192*2,192*2,kernel_size=3,padding=1),nn.ReLU(),\n",
    "      nn.Conv2d(192*2,256,kernel_size=3,padding=1),nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=3,stride=2), # 6*6*256\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(6*6*256,2048*2),nn.ReLU(),nn.Dropout(p=0.5),\n",
    "      nn.Linear(2048*2,2048*2),nn.ReLU(),nn.Dropout(p=0.5),#全连接层通常相比卷积层有巨量的参数，非常容易过拟合，因此需要dropout惩罚，防止过拟合，相当于减小了一半的参数数量\n",
    "      nn.Linear(2048*2,10),nn.ReLU(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ee53b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04adc06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): ReLU()\n",
       "  (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): ReLU()\n",
       "  (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU()\n",
       "  (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (13): Flatten(start_dim=1, end_dim=-1)\n",
       "  (14): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "  (15): ReLU()\n",
       "  (16): Dropout(p=0.5, inplace=False)\n",
       "  (17): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (18): ReLU()\n",
       "  (19): Dropout(p=0.5, inplace=False)\n",
       "  (20): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  (21): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlexNet.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aade71f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim=torch.optim.SGD(AlexNet.parameters(),lr=0.01)\n",
    "loss=torch.nn.CrossEntropyLoss()\n",
    "loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42f9dcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.2996, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5355/706273932.py:56: UserWarning: Attempting to set identical left == right == 0 results in singular transformations; automatically expanding.\n",
      "  ax.set_xlim(0, max(xdata))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.2996, 1.2494, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000])\n",
      "tensor([2.2996, 1.2494, 0.9125, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000])\n",
      "tensor([2.2996, 1.2494, 0.9125, 0.7919, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000])\n",
      "tensor([2.2996, 1.2494, 0.9125, 0.7919, 0.6440, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000])\n",
      "tensor([2.2996, 1.2494, 0.9125, 0.7919, 0.6440, 0.5759, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000])\n",
      "tensor([2.2996, 1.2494, 0.9125, 0.7919, 0.6440, 0.5759, 0.5335, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000])\n",
      "tensor([2.2996, 1.2494, 0.9125, 0.7919, 0.6440, 0.5759, 0.5335, 0.5114, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000])\n",
      "tensor([2.2996, 1.2494, 0.9125, 0.7919, 0.6440, 0.5759, 0.5335, 0.5114, 0.4957,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000])\n",
      "tensor([2.2996, 1.2494, 0.9125, 0.7919, 0.6440, 0.5759, 0.5335, 0.5114, 0.4957,\n",
      "        0.4387, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000])\n",
      "tensor([2.2996, 1.2494, 0.9125, 0.7919, 0.6440, 0.5759, 0.5335, 0.5114, 0.4957,\n",
      "        0.4387, 0.4346, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000])\n",
      "tensor([2.2996, 1.2494, 0.9125, 0.7919, 0.6440, 0.5759, 0.5335, 0.5114, 0.4957,\n",
      "        0.4387, 0.4346, 0.4281, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "#创建曲线图并初始化\n",
    "xdata=[]\n",
    "ydata=[]\n",
    "xdataTest=[]\n",
    "ydataTest=[]\n",
    "fig, ax = pyp.subplots()\n",
    "line, = ax.plot(xdata, ydata,color='blue')\n",
    "line2, = ax.plot(xdataTest, ydataTest,color='red')\n",
    "pyp.title(\"Loss\")\n",
    "pyp.xlabel(\"epoch\")\n",
    "pyp.ylabel(\"Loss\")\n",
    "pyp.grid()\n",
    "ax.legend((line,line2),('trainLoss','testLoss'))\n",
    "#动态更新曲线训练函数\n",
    "num_epoch=22\n",
    "aveLoss=torch.zeros(num_epoch)\n",
    "aveLoss=aveLoss.detach().numpy()\n",
    "aveLossTest=torch.zeros(num_epoch)\n",
    "# aveLossTest=aveLoss.detach().numpy()\n",
    "def animationTrain(epoch):\n",
    "    #每epoch训练代码区#\n",
    "    sumLoss=0\n",
    "    trainnum=0;\n",
    "    if epoch>0:\n",
    "        for trainData,trainLabel in trainLoader:\n",
    "            optim.zero_grad()\n",
    "            trainLabel=trainLabel.to(torch.device(\"cuda:0\"))\n",
    "            trainData=trainData.to(torch.device(\"cuda:0\"))\n",
    "            comLoss=loss(AlexNet(trainData),trainLabel)\n",
    "            comLoss.backward()\n",
    "            optim.step()\n",
    "            sumLoss=comLoss+sumLoss\n",
    "            trainnum=trainnum+1\n",
    "        aveLoss[epoch-1]=(sumLoss.to(torch.device(\"cpu\"))/trainnum)\n",
    "\n",
    "        sumLoss=0\n",
    "        trainnum=0\n",
    "        with torch.no_grad():\n",
    "            for trainData,trainLabel in testLoader:\n",
    "                trainLabel=trainLabel.to(torch.device(\"cuda:0\"))\n",
    "                trainData=trainData.to(torch.device(\"cuda:0\"))\n",
    "                comLoss=loss(AlexNet(trainData),trainLabel)\n",
    "                sumLoss=comLoss+sumLoss\n",
    "                trainnum=trainnum+1\n",
    "        aveLossTest[epoch-1]=(sumLoss.to(torch.device(\"cpu\"))/trainnum)   \n",
    "        print(aveLossTest)\n",
    "        #图表数据更新#\n",
    "        xdata.append(epoch-1)\n",
    "        ydata.append(aveLoss[epoch-1])\n",
    "        xdataTest.append(epoch-1)\n",
    "        ydataTest.append(aveLossTest[epoch-1])\n",
    "        line.set_xdata(xdata)\n",
    "        line.set_ydata(ydata)\n",
    "        line2.set_xdata(xdataTest)\n",
    "        line2.set_ydata(ydataTest)\n",
    "        ax.set_xlim(0, max(xdata))\n",
    "        ax.set_ylim(0, max(ydata))\n",
    "        #print(aveLoss[epoch])\n",
    "        return line,line2,\n",
    "#创建动画对象并显示，显示过程逐次调用Trian函数\n",
    "anim = animation.FuncAnimation(fig, animationTrain, interval=20, blit=False,repeat=False,frames=num_epoch)\n",
    "pyp.show()     \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
